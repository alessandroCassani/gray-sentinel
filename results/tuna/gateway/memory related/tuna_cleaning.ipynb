{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats as scipy_stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load BASELINE datasets\n",
    "df_baseline_mem_available = pd.read_csv(\"baseline/mem_available.csv\")\n",
    "df_baseline_mem_cache = pd.read_csv(\"baseline/mem_cache.csv\")\n",
    "df_baseline_mem_util = pd.read_csv(\"baseline/mem_util.csv\")\n",
    "\n",
    "# Load CPU STRESS datasets\n",
    "df_cpustress_mem_available = pd.read_csv(\"cpu stress/mem_available.csv\")\n",
    "df_cpustress_mem_cache = pd.read_csv(\"cpu stress/mem_cache.csv\")\n",
    "df_cpustress_mem_util = pd.read_csv(\"cpu stress/mem_util.csv\")\n",
    "\n",
    "# Load DELAY datasets\n",
    "df_delay_mem_available = pd.read_csv(\"delay/mem_available.csv\")\n",
    "df_delay_mem_cache = pd.read_csv(\"delay/mem_cache.csv\")\n",
    "df_delay_mem_util = pd.read_csv(\"delay/mem_util.csv\")\n",
    "\n",
    "# Load MEM STRESS datasets\n",
    "df_memstress_mem_available = pd.read_csv(\"mem stress/mem_available.csv\")\n",
    "df_memstress_mem_cache = pd.read_csv(\"mem stress/mem_cache.csv\")\n",
    "df_memstress_mem_util = pd.read_csv(\"mem stress/mem_util.csv\")\n",
    "\n",
    "# Load NET LOSS datasets\n",
    "df_netloss_mem_available = pd.read_csv(\"netloss/mem_available.csv\")\n",
    "df_netloss_mem_cache = pd.read_csv(\"netloss/mem_cache.csv\")\n",
    "df_netloss_mem_util = pd.read_csv(\"netloss/mem_util.csv\")\n",
    "\n",
    "\n",
    "# Add source labels - BASELINE\n",
    "df_baseline_mem_available[\"source\"] = \"BASELINE\"\n",
    "df_baseline_mem_cache[\"source\"] = \"BASELINE\"\n",
    "df_baseline_mem_util[\"source\"] = \"BASELINE\"\n",
    "\n",
    "# Add source labels - CPU STRESS\n",
    "df_cpustress_mem_available[\"source\"] = \"CPU_STRESS\"\n",
    "df_cpustress_mem_cache[\"source\"] = \"CPU_STRESS\"\n",
    "df_cpustress_mem_util[\"source\"] = \"CPU_STRESS\"\n",
    "\n",
    "# Add source labels - DELAY\n",
    "df_delay_mem_available[\"source\"] = \"DELAY\"\n",
    "df_delay_mem_cache[\"source\"] = \"DELAY\"\n",
    "df_delay_mem_util[\"source\"] = \"DELAY\"\n",
    "\n",
    "# Add source labels - MEM STRESS\n",
    "df_memstress_mem_available[\"source\"] = \"MEM_STRESS\"\n",
    "df_memstress_mem_cache[\"source\"] = \"MEM_STRESS\"\n",
    "df_memstress_mem_util[\"source\"] = \"MEM_STRESS\"\n",
    "\n",
    "# Add source labels - NET LOSS\n",
    "df_netloss_mem_available[\"source\"] = \"NET_LOSS\"\n",
    "df_netloss_mem_cache[\"source\"] = \"NET_LOSS\"\n",
    "df_netloss_mem_util[\"source\"] = \"NET_LOSS\"\n",
    "\n",
    "\n",
    "# Convert to datetime - BASELINE\n",
    "df_baseline_mem_available[\"Time\"] = pd.to_datetime(df_baseline_mem_available[\"Time\"])\n",
    "df_baseline_mem_cache[\"Time\"] = pd.to_datetime(df_baseline_mem_cache[\"Time\"])\n",
    "df_baseline_mem_util[\"Time\"] = pd.to_datetime(df_baseline_mem_util[\"Time\"])\n",
    "\n",
    "# Convert to datetime - CPU STRESS\n",
    "df_cpustress_mem_available[\"Time\"] = pd.to_datetime(df_cpustress_mem_available[\"Time\"])\n",
    "df_cpustress_mem_cache[\"Time\"] = pd.to_datetime(df_cpustress_mem_cache[\"Time\"])\n",
    "df_cpustress_mem_util[\"Time\"] = pd.to_datetime(df_cpustress_mem_util[\"Time\"])\n",
    "\n",
    "# Convert to datetime - DELAY\n",
    "df_delay_mem_available[\"Time\"] = pd.to_datetime(df_delay_mem_available[\"Time\"])\n",
    "df_delay_mem_cache[\"Time\"] = pd.to_datetime(df_delay_mem_cache[\"Time\"])\n",
    "df_delay_mem_util[\"Time\"] = pd.to_datetime(df_delay_mem_util[\"Time\"])\n",
    "\n",
    "# Convert to datetime - MEM STRESS\n",
    "df_memstress_mem_available[\"Time\"] = pd.to_datetime(df_memstress_mem_available[\"Time\"])\n",
    "df_memstress_mem_cache[\"Time\"] = pd.to_datetime(df_memstress_mem_cache[\"Time\"])\n",
    "df_memstress_mem_util[\"Time\"] = pd.to_datetime(df_memstress_mem_util[\"Time\"])\n",
    "\n",
    "# Convert to datetime - NET LOSS\n",
    "df_netloss_mem_available[\"Time\"] = pd.to_datetime(df_netloss_mem_available[\"Time\"])\n",
    "df_netloss_mem_cache[\"Time\"] = pd.to_datetime(df_netloss_mem_cache[\"Time\"])\n",
    "df_netloss_mem_util[\"Time\"] = pd.to_datetime(df_netloss_mem_util[\"Time\"])\n",
    "\n",
    "\n",
    "delay = 30\n",
    "duration = 50\n",
    "\n",
    "# Synchronize all datasets with baseline timeline\n",
    "time_offset = df_baseline_mem_available[\"Time\"].min()\n",
    "\n",
    "# Synchronize CPU STRESS datasets\n",
    "cpustress_offset = time_offset - df_cpustress_mem_available[\"Time\"].min()\n",
    "df_cpustress_mem_available[\"Time\"] += cpustress_offset\n",
    "df_cpustress_mem_cache[\"Time\"] += cpustress_offset\n",
    "df_cpustress_mem_util[\"Time\"] += cpustress_offset\n",
    "\n",
    "# Synchronize DELAY datasets\n",
    "delay_offset = time_offset - df_delay_mem_available[\"Time\"].min()\n",
    "df_delay_mem_available[\"Time\"] += delay_offset\n",
    "df_delay_mem_cache[\"Time\"] += delay_offset\n",
    "df_delay_mem_util[\"Time\"] += delay_offset\n",
    "\n",
    "# Synchronize MEM STRESS datasets\n",
    "memstress_offset = time_offset - df_memstress_mem_available[\"Time\"].min()\n",
    "df_memstress_mem_available[\"Time\"] += memstress_offset\n",
    "df_memstress_mem_cache[\"Time\"] += memstress_offset\n",
    "df_memstress_mem_util[\"Time\"] += memstress_offset\n",
    "\n",
    "# Synchronize NET LOSS datasets\n",
    "netloss_offset = time_offset - df_netloss_mem_available[\"Time\"].min()\n",
    "df_netloss_mem_available[\"Time\"] += netloss_offset\n",
    "df_netloss_mem_cache[\"Time\"] += netloss_offset\n",
    "df_netloss_mem_util[\"Time\"] += netloss_offset\n",
    "\n",
    "\n",
    "# Convert timeline to minutes for ALL datasets\n",
    "all_dfs = [\n",
    "    # Baseline\n",
    "    df_baseline_mem_available, df_baseline_mem_cache, df_baseline_mem_util,\n",
    "    # CPU Stress\n",
    "    df_cpustress_mem_available, df_cpustress_mem_cache, df_cpustress_mem_util,\n",
    "    # Delay\n",
    "    df_delay_mem_available, df_delay_mem_cache, df_delay_mem_util,\n",
    "    # Memory Stress\n",
    "    df_memstress_mem_available, df_memstress_mem_cache, df_memstress_mem_util,\n",
    "    # Network Loss\n",
    "    df_netloss_mem_available, df_netloss_mem_cache, df_netloss_mem_util\n",
    "]\n",
    "\n",
    "for df in all_dfs:\n",
    "    df[\"Minutes\"] = (df[\"Time\"] - df[\"Time\"].min()).dt.total_seconds() / 60\n",
    "\n",
    "# COMPLETE DATASETS DICTIONARY \n",
    "all_datasets = {\n",
    "    'MemAvailable': {\n",
    "        'baseline': df_baseline_mem_available,\n",
    "        'cpu_stress': df_cpustress_mem_available,\n",
    "        'delay': df_delay_mem_available,\n",
    "        'mem_stress': df_memstress_mem_available,\n",
    "        'net_loss': df_netloss_mem_available,\n",
    "    },\n",
    "    'MemCache': {\n",
    "        'baseline': df_baseline_mem_cache,\n",
    "        'cpu_stress': df_cpustress_mem_cache,\n",
    "        'delay': df_delay_mem_cache,\n",
    "        'mem_stress': df_memstress_mem_cache,\n",
    "        'net_loss': df_netloss_mem_cache,\n",
    "    },\n",
    "    'MemUtil': {\n",
    "        'baseline': df_baseline_mem_util,\n",
    "        'cpu_stress': df_cpustress_mem_util,\n",
    "        'delay': df_delay_mem_util,\n",
    "        'mem_stress': df_memstress_mem_util,\n",
    "        'net_loss': df_netloss_mem_util,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… All memory datasets loaded successfully!\")\n",
    "print(f\"ðŸ“Š Loaded {len(all_datasets)} memory metrics across {len(all_datasets['MemAvailable'])} experiment types\")\n",
    "print(\"\\nDataset structure:\")\n",
    "for metric, experiments in all_datasets.items():\n",
    "    print(f\"  {metric}: {list(experiments.keys())}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
