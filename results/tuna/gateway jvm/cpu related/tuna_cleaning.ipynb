{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3044dc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All datasets loaded successfully!\n",
      "ðŸ“Š Loaded 5 metrics across 5 experiment types\n",
      "\n",
      "Dataset structure:\n",
      "  IOWait: ['baseline', 'cache_filling', 'gc_stress', 'oom', 'threadfull']\n",
      "  IRQ: ['baseline', 'cache_filling', 'gc_stress', 'oom', 'threadfull']\n",
      "  System: ['baseline', 'cache_filling', 'gc_stress', 'oom', 'threadfull']\n",
      "  User: ['baseline', 'cache_filling', 'gc_stress', 'oom', 'threadfull']\n",
      "  Utilization: ['baseline', 'cache_filling', 'gc_stress', 'oom', 'threadfull']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats as scipy_stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "from typing import Dict, List, Any \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load BASELINE datasets\n",
    "df_baseline_iowait = pd.read_csv(\"baseline/cpu_iowait.csv\")\n",
    "df_baseline_irq = pd.read_csv(\"baseline/cpu_irq.csv\")\n",
    "df_baseline_system_msec = pd.read_csv(\"baseline/cpu_system_msec.csv\")\n",
    "df_baseline_user_msec = pd.read_csv(\"baseline/cpu_user_msec.csv\")\n",
    "df_baseline_util_per = pd.read_csv(\"baseline/cpu_util_per.csv\")\n",
    "\n",
    "# Load CACHE FILLING datasets\n",
    "df_cachefilling_iowait = pd.read_csv(\"cache filling/cpu_iowait.csv\")\n",
    "df_cachefilling_irq = pd.read_csv(\"cache filling/cpu_irq.csv\")\n",
    "df_cachefilling_system_msec = pd.read_csv(\"cache filling/cpu_system_msec.csv\")\n",
    "df_cachefilling_user_msec = pd.read_csv(\"cache filling/cpu_user_msec.csv\")\n",
    "df_cachefilling_util_per = pd.read_csv(\"cache filling/cpu_util_per.csv\")\n",
    "\n",
    "# Load GC STRESS datasets\n",
    "df_gcstress_iowait = pd.read_csv(\"gc stress/cpu_iowait.csv\")\n",
    "df_gcstress_irq = pd.read_csv(\"gc stress/cpu_irq.csv\")\n",
    "df_gcstress_system_msec = pd.read_csv(\"gc stress/cpu_system_msec.csv\")\n",
    "df_gcstress_user_msec = pd.read_csv(\"gc stress/cpu_user_msec.csv\")\n",
    "df_gcstress_util_per = pd.read_csv(\"gc stress/cpu_util_per.csv\")\n",
    "\n",
    "# Load OOM datasets\n",
    "df_oom_iowait = pd.read_csv(\"oom/cpu_iowait.csv\")\n",
    "df_oom_irq = pd.read_csv(\"oom/cpu_irq.csv\")\n",
    "df_oom_system_msec = pd.read_csv(\"oom/cpu_system_msec.csv\")\n",
    "df_oom_user_msec = pd.read_csv(\"oom/cpu_user_msec.csv\")\n",
    "df_oom_util_per = pd.read_csv(\"oom/cpu_util_per.csv\")\n",
    "\n",
    "# Load THREADFULL datasets\n",
    "df_threadfull_iowait = pd.read_csv(\"threadfull/cpu_iowait.csv\")\n",
    "df_threadfull_irq = pd.read_csv(\"threadfull/cpu_irq.csv\")\n",
    "df_threadfull_system_msec = pd.read_csv(\"threadfull/cpu_system_msec.csv\")\n",
    "df_threadfull_user_msec = pd.read_csv(\"threadfull/cpu_user_msec.csv\")\n",
    "df_threadfull_util_per = pd.read_csv(\"threadfull/cpu_util_per.csv\")\n",
    "\n",
    "\n",
    "# Add source labels - BASELINE\n",
    "df_baseline_iowait[\"source\"] = \"BASELINE\"\n",
    "df_baseline_irq[\"source\"] = \"BASELINE\"\n",
    "df_baseline_system_msec[\"source\"] = \"BASELINE\"\n",
    "df_baseline_user_msec[\"source\"] = \"BASELINE\"\n",
    "df_baseline_util_per[\"source\"] = \"BASELINE\"\n",
    "\n",
    "# Add source labels - CACHE FILLING\n",
    "df_cachefilling_iowait[\"source\"] = \"CACHE_FILLING\"\n",
    "df_cachefilling_irq[\"source\"] = \"CACHE_FILLING\"\n",
    "df_cachefilling_system_msec[\"source\"] = \"CACHE_FILLING\"\n",
    "df_cachefilling_user_msec[\"source\"] = \"CACHE_FILLING\"\n",
    "df_cachefilling_util_per[\"source\"] = \"CACHE_FILLING\"\n",
    "\n",
    "# Add source labels - GC STRESS\n",
    "df_gcstress_iowait[\"source\"] = \"GC_STRESS\"\n",
    "df_gcstress_irq[\"source\"] = \"GC_STRESS\"\n",
    "df_gcstress_system_msec[\"source\"] = \"GC_STRESS\"\n",
    "df_gcstress_user_msec[\"source\"] = \"GC_STRESS\"\n",
    "df_gcstress_util_per[\"source\"] = \"GC_STRESS\"\n",
    "\n",
    "# Add source labels - OOM\n",
    "df_oom_iowait[\"source\"] = \"OOM\"\n",
    "df_oom_irq[\"source\"] = \"OOM\"\n",
    "df_oom_system_msec[\"source\"] = \"OOM\"\n",
    "df_oom_user_msec[\"source\"] = \"OOM\"\n",
    "df_oom_util_per[\"source\"] = \"OOM\"\n",
    "\n",
    "# Add source labels - THREADFULL\n",
    "df_threadfull_iowait[\"source\"] = \"THREADFULL\"\n",
    "df_threadfull_irq[\"source\"] = \"THREADFULL\"\n",
    "df_threadfull_system_msec[\"source\"] = \"THREADFULL\"\n",
    "df_threadfull_user_msec[\"source\"] = \"THREADFULL\"\n",
    "df_threadfull_util_per[\"source\"] = \"THREADFULL\"\n",
    "\n",
    "\n",
    "# Convert to datetime - BASELINE\n",
    "df_baseline_iowait[\"Time\"] = pd.to_datetime(df_baseline_iowait[\"Time\"])\n",
    "df_baseline_irq[\"Time\"] = pd.to_datetime(df_baseline_irq[\"Time\"])\n",
    "df_baseline_system_msec[\"Time\"] = pd.to_datetime(df_baseline_system_msec[\"Time\"])\n",
    "df_baseline_user_msec[\"Time\"] = pd.to_datetime(df_baseline_user_msec[\"Time\"])\n",
    "df_baseline_util_per[\"Time\"] = pd.to_datetime(df_baseline_util_per[\"Time\"])\n",
    "\n",
    "# Convert to datetime - CACHE FILLING\n",
    "df_cachefilling_iowait[\"Time\"] = pd.to_datetime(df_cachefilling_iowait[\"Time\"])\n",
    "df_cachefilling_irq[\"Time\"] = pd.to_datetime(df_cachefilling_irq[\"Time\"])\n",
    "df_cachefilling_system_msec[\"Time\"] = pd.to_datetime(df_cachefilling_system_msec[\"Time\"])\n",
    "df_cachefilling_user_msec[\"Time\"] = pd.to_datetime(df_cachefilling_user_msec[\"Time\"])\n",
    "df_cachefilling_util_per[\"Time\"] = pd.to_datetime(df_cachefilling_util_per[\"Time\"])\n",
    "\n",
    "# Convert to datetime - GC STRESS\n",
    "df_gcstress_iowait[\"Time\"] = pd.to_datetime(df_gcstress_iowait[\"Time\"])\n",
    "df_gcstress_irq[\"Time\"] = pd.to_datetime(df_gcstress_irq[\"Time\"])\n",
    "df_gcstress_system_msec[\"Time\"] = pd.to_datetime(df_gcstress_system_msec[\"Time\"])\n",
    "df_gcstress_user_msec[\"Time\"] = pd.to_datetime(df_gcstress_user_msec[\"Time\"])\n",
    "df_gcstress_util_per[\"Time\"] = pd.to_datetime(df_gcstress_util_per[\"Time\"])\n",
    "\n",
    "# Convert to datetime - OOM\n",
    "df_oom_iowait[\"Time\"] = pd.to_datetime(df_oom_iowait[\"Time\"])\n",
    "df_oom_irq[\"Time\"] = pd.to_datetime(df_oom_irq[\"Time\"])\n",
    "df_oom_system_msec[\"Time\"] = pd.to_datetime(df_oom_system_msec[\"Time\"])\n",
    "df_oom_user_msec[\"Time\"] = pd.to_datetime(df_oom_user_msec[\"Time\"])\n",
    "df_oom_util_per[\"Time\"] = pd.to_datetime(df_oom_util_per[\"Time\"])\n",
    "\n",
    "# Convert to datetime - THREADFULL\n",
    "df_threadfull_iowait[\"Time\"] = pd.to_datetime(df_threadfull_iowait[\"Time\"])\n",
    "df_threadfull_irq[\"Time\"] = pd.to_datetime(df_threadfull_irq[\"Time\"])\n",
    "df_threadfull_system_msec[\"Time\"] = pd.to_datetime(df_threadfull_system_msec[\"Time\"])\n",
    "df_threadfull_user_msec[\"Time\"] = pd.to_datetime(df_threadfull_user_msec[\"Time\"])\n",
    "df_threadfull_util_per[\"Time\"] = pd.to_datetime(df_threadfull_util_per[\"Time\"])\n",
    "\n",
    "\n",
    "delay = 30\n",
    "duration = 50\n",
    "\n",
    "# Synchronize all datasets with baseline timeline\n",
    "time_offset = df_baseline_iowait[\"Time\"].min()\n",
    "\n",
    "# Synchronize CACHE FILLING datasets\n",
    "cachefilling_offset = time_offset - df_cachefilling_iowait[\"Time\"].min()\n",
    "df_cachefilling_iowait[\"Time\"] += cachefilling_offset\n",
    "df_cachefilling_irq[\"Time\"] += cachefilling_offset\n",
    "df_cachefilling_system_msec[\"Time\"] += cachefilling_offset\n",
    "df_cachefilling_user_msec[\"Time\"] += cachefilling_offset\n",
    "df_cachefilling_util_per[\"Time\"] += cachefilling_offset\n",
    "\n",
    "# Synchronize GC STRESS datasets\n",
    "gcstress_offset = time_offset - df_gcstress_iowait[\"Time\"].min()\n",
    "df_gcstress_iowait[\"Time\"] += gcstress_offset\n",
    "df_gcstress_irq[\"Time\"] += gcstress_offset\n",
    "df_gcstress_system_msec[\"Time\"] += gcstress_offset\n",
    "df_gcstress_user_msec[\"Time\"] += gcstress_offset\n",
    "df_gcstress_util_per[\"Time\"] += gcstress_offset\n",
    "\n",
    "# Synchronize OOM datasets\n",
    "oom_offset = time_offset - df_oom_iowait[\"Time\"].min()\n",
    "df_oom_iowait[\"Time\"] += oom_offset\n",
    "df_oom_irq[\"Time\"] += oom_offset\n",
    "df_oom_system_msec[\"Time\"] += oom_offset\n",
    "df_oom_user_msec[\"Time\"] += oom_offset\n",
    "df_oom_util_per[\"Time\"] += oom_offset\n",
    "\n",
    "# Synchronize THREADFULL datasets\n",
    "threadfull_offset = time_offset - df_threadfull_iowait[\"Time\"].min()\n",
    "df_threadfull_iowait[\"Time\"] += threadfull_offset\n",
    "df_threadfull_irq[\"Time\"] += threadfull_offset\n",
    "df_threadfull_system_msec[\"Time\"] += threadfull_offset\n",
    "df_threadfull_user_msec[\"Time\"] += threadfull_offset\n",
    "df_threadfull_util_per[\"Time\"] += threadfull_offset\n",
    "\n",
    "\n",
    "# Convert timeline to minutes for ALL datasets\n",
    "all_dfs = [\n",
    "    df_baseline_iowait, df_baseline_irq, df_baseline_system_msec, df_baseline_user_msec, df_baseline_util_per,\n",
    "    df_cachefilling_iowait, df_cachefilling_irq, df_cachefilling_system_msec, df_cachefilling_user_msec, df_cachefilling_util_per,\n",
    "    df_gcstress_iowait, df_gcstress_irq, df_gcstress_system_msec, df_gcstress_user_msec, df_gcstress_util_per,\n",
    "    df_oom_iowait, df_oom_irq, df_oom_system_msec, df_oom_user_msec, df_oom_util_per,\n",
    "    df_threadfull_iowait, df_threadfull_irq, df_threadfull_system_msec, df_threadfull_user_msec, df_threadfull_util_per\n",
    "]\n",
    "\n",
    "for df in all_dfs:\n",
    "    df[\"Minutes\"] = (df[\"Time\"] - df[\"Time\"].min()).dt.total_seconds() / 60\n",
    "\n",
    "# COMPLETE DATASETS DICTIONARY \n",
    "all_datasets = {\n",
    "    'IOWait': {\n",
    "        'baseline': df_baseline_iowait,\n",
    "        'cache_filling': df_cachefilling_iowait,\n",
    "        'gc_stress': df_gcstress_iowait,\n",
    "        'oom': df_oom_iowait,\n",
    "        'threadfull': df_threadfull_iowait,\n",
    "    },\n",
    "    'IRQ': {\n",
    "        'baseline': df_baseline_irq,\n",
    "        'cache_filling': df_cachefilling_irq,\n",
    "        'gc_stress': df_gcstress_irq,\n",
    "        'oom': df_oom_irq,\n",
    "        'threadfull': df_threadfull_irq,\n",
    "    },\n",
    "    'System': {\n",
    "        'baseline': df_baseline_system_msec,\n",
    "        'cache_filling': df_cachefilling_system_msec,\n",
    "        'gc_stress': df_gcstress_system_msec,\n",
    "        'oom': df_oom_system_msec,\n",
    "        'threadfull': df_threadfull_system_msec,\n",
    "    },\n",
    "    'User': {\n",
    "        'baseline': df_baseline_user_msec,\n",
    "        'cache_filling': df_cachefilling_user_msec,\n",
    "        'gc_stress': df_gcstress_user_msec,\n",
    "        'oom': df_oom_user_msec,\n",
    "        'threadfull': df_threadfull_user_msec,\n",
    "    },\n",
    "    'Utilization': {\n",
    "        'baseline': df_baseline_util_per,\n",
    "        'cache_filling': df_cachefilling_util_per,\n",
    "        'gc_stress': df_gcstress_util_per,\n",
    "        'oom': df_oom_util_per,\n",
    "        'threadfull': df_threadfull_util_per,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… All datasets loaded successfully!\")\n",
    "print(f\"ðŸ“Š Loaded {len(all_datasets)} metrics across {len(all_datasets['IOWait'])} experiment types\")\n",
    "print(\"\\nDataset structure:\")\n",
    "for metric, experiments in all_datasets.items():\n",
    "    print(f\"  {metric}: {list(experiments.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6fc75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuna_parameters(metric_name, experiment_type):\n",
    "    \"\"\"Get consistent TUNA parameters for a metric and experiment\"\"\"\n",
    "    \n",
    "    if \"iowait\" in metric_name.lower():\n",
    "        window_size = 3       #3 3.1\n",
    "        threshold = 3.0\n",
    "    elif \"irq\" in metric_name.lower():\n",
    "        window_size = 4         #4 0.8\n",
    "        threshold = 0.8\n",
    "    elif \"system\" in metric_name.lower():\n",
    "        window_size = 20\n",
    "        threshold = 1.1\n",
    "    elif \"user\" in metric_name.lower():\n",
    "        window_size = 20\n",
    "        threshold = 0.8\n",
    "    elif \"utilization\" in metric_name.lower():\n",
    "        window_size = 30\n",
    "        threshold = 0.5\n",
    "\n",
    "    \n",
    "    min_absolute_range_factor = 0.4\n",
    "    penalty_factor = 0.5\n",
    "    lookback_window = 10\n",
    "    \n",
    "    return {\n",
    "        'window_size': window_size,\n",
    "        'threshold': threshold,\n",
    "        'min_absolute_range_factor': min_absolute_range_factor,\n",
    "        'penalty_factor': penalty_factor,\n",
    "        'lookback_window': min(lookback_window, 15)\n",
    "    }\n",
    "\n",
    "def detect_outliers_tuna_memory(timeseries, metric_name=\"\", experiment_type=\"\"):\n",
    "    \"\"\"TUNA's relative range outlier detection with MIN/MAX marking\"\"\"\n",
    "    \n",
    "    outlier_mask = np.zeros(len(timeseries), dtype=bool)\n",
    "    params = get_tuna_parameters(metric_name, experiment_type)\n",
    "    \n",
    "    window_size = params['window_size']\n",
    "    threshold = params['threshold']\n",
    "    min_absolute_range = params['min_absolute_range_factor'] * np.std(timeseries)\n",
    "    \n",
    "    # Analyze windows with sliding step (step=1)\n",
    "    for i in range(0, len(timeseries) - window_size + 1, 1):\n",
    "        window = timeseries[i:i + window_size]\n",
    "        window_mean = np.mean(window)\n",
    "        window_range = np.max(window) - np.min(window)\n",
    "        \n",
    "        if window_mean > 0:\n",
    "            relative_range = window_range / window_mean\n",
    "            \n",
    "            # Apply outlier detection\n",
    "            if relative_range > threshold and window_range > min_absolute_range:\n",
    "                window_max = np.max(window)\n",
    "                window_min = np.min(window)\n",
    "                \n",
    "                # Mark only min/max values as outliers\n",
    "                for j in range(window_size):\n",
    "                    actual_idx = i + j\n",
    "                    if actual_idx < len(timeseries):\n",
    "                        if (timeseries[actual_idx] == window_max or \n",
    "                            timeseries[actual_idx] == window_min):\n",
    "                            outlier_mask[actual_idx] = True\n",
    "    \n",
    "    return outlier_mask\n",
    "\n",
    "def get_local_stable_baseline(timeseries, stable_mask, current_idx, lookback_window):\n",
    "    \"\"\"Get local baseline from recent stable points - simplified strategy\"\"\"\n",
    "    \n",
    "    # Look backwards for recent stable points\n",
    "    start_idx = max(0, current_idx - lookback_window)\n",
    "    local_window = timeseries[start_idx:current_idx]\n",
    "    local_stable_mask = stable_mask[start_idx:current_idx]\n",
    "    \n",
    "    recent_stable = local_window[local_stable_mask]\n",
    "    \n",
    "    if len(recent_stable) >= 3:\n",
    "        return np.median(recent_stable)\n",
    "    elif len(recent_stable) >= 1:\n",
    "        return np.mean(recent_stable)\n",
    "    \n",
    "    # If no recent stable points, look forward\n",
    "    end_idx = min(len(timeseries), current_idx + lookback_window)\n",
    "    forward_window = timeseries[current_idx+1:end_idx]\n",
    "    forward_stable_mask = stable_mask[current_idx+1:end_idx]\n",
    "    \n",
    "    forward_stable = forward_window[forward_stable_mask]\n",
    "    \n",
    "    if len(forward_stable) >= 1:\n",
    "        return np.median(forward_stable) if len(forward_stable) >= 3 else np.mean(forward_stable)\n",
    "    \n",
    "    # Fallback to global median of stable values\n",
    "    stable_values = timeseries[stable_mask]\n",
    "    return np.median(stable_values) if len(stable_values) > 0 else np.median(timeseries)\n",
    "\n",
    "def apply_penalty_local_trend(timeseries, outlier_mask, metric_name=\"\", experiment_type=\"\"):\n",
    "    \"\"\"Apply penalty based on local stable trend\"\"\"\n",
    "    \n",
    "    cleaned_series = timeseries.copy()\n",
    "    stable_mask = ~outlier_mask\n",
    "    params = get_tuna_parameters(metric_name, experiment_type)\n",
    "    \n",
    "    effective_penalty = params['penalty_factor']\n",
    "    lookback_window = params['lookback_window']\n",
    "    \n",
    "    for i in range(len(timeseries)):\n",
    "        if outlier_mask[i]:\n",
    "            local_baseline = get_local_stable_baseline(timeseries, stable_mask, i, lookback_window)\n",
    "            original_value = timeseries[i]\n",
    "            deviation = original_value - local_baseline\n",
    "            cleaned_series[i] = local_baseline + deviation * effective_penalty\n",
    "    \n",
    "    return cleaned_series\n",
    "\n",
    "def create_features_for_ml(timeseries, stable_mask, experiment_type):\n",
    "    \"\"\"Create features ONLY from stable regions\"\"\"\n",
    "    \n",
    "    features = []\n",
    "    feature_indices = []\n",
    "    window_size = 3  # Fixed feature window size\n",
    "    \n",
    "    for i in range(window_size, len(timeseries)):\n",
    "        if stable_mask[i]:\n",
    "            window = timeseries[i-window_size:i]\n",
    "            window_stable_mask = stable_mask[i-window_size:i]\n",
    "            \n",
    "            # Only create features if at least 80% of the window is stable\n",
    "            stable_ratio = np.sum(window_stable_mask) / len(window_stable_mask)\n",
    "            if stable_ratio >= 0.8:\n",
    "                stable_window = window[window_stable_mask]\n",
    "                \n",
    "                if len(stable_window) > 0:\n",
    "                    feature_vector = [\n",
    "                        np.mean(stable_window),\n",
    "                        np.std(stable_window),\n",
    "                        np.median(stable_window),\n",
    "                        np.max(stable_window) - np.min(stable_window),\n",
    "                        timeseries[i-1] if stable_mask[i-1] else np.mean(stable_window),\n",
    "                        i / len(timeseries),\n",
    "                    ]\n",
    "                    \n",
    "                    # Clean any NaN/inf values\n",
    "                    feature_vector = [0.0 if np.isnan(val) or np.isinf(val) else float(val) for val in feature_vector]\n",
    "                    \n",
    "                    # Experiment type encoding\n",
    "                    exp_features = [0, 0, 0, 0, 0]\n",
    "                    if experiment_type == \"baseline\":\n",
    "                        exp_features[0] = 1\n",
    "                    elif experiment_type == \"cache_filling\":\n",
    "                        exp_features[1] = 1\n",
    "                    elif experiment_type == \"gc_stress\":\n",
    "                        exp_features[2] = 1\n",
    "                    elif experiment_type == \"oom\":\n",
    "                        exp_features[3] = 1\n",
    "                    elif experiment_type == \"threadfull\":\n",
    "                        exp_features[4] = 1\n",
    "                    \n",
    "                    feature_vector.extend(exp_features)\n",
    "                    features.append(feature_vector)\n",
    "                    feature_indices.append(i)\n",
    "    \n",
    "    return np.array(features), np.array(feature_indices)\n",
    "\n",
    "def apply_tuna_to_single_series(cumulative, exp_name, model, scaler, metric_name=\"\"):\n",
    "    \"\"\"Apply TUNA cleaning to a single series\"\"\"\n",
    "    \n",
    "    # Phase 1: Identify outliers\n",
    "    outlier_mask = detect_outliers_tuna_memory(cumulative, metric_name=metric_name, experiment_type=exp_name)\n",
    "    stable_mask = ~outlier_mask\n",
    "    outliers_count = np.sum(outlier_mask)\n",
    "    \n",
    "    # Phase 2: Apply penalty\n",
    "    cleaned_series = cumulative.copy()\n",
    "    if outliers_count > 0:\n",
    "        cleaned_series = apply_penalty_local_trend(cumulative, outlier_mask, metric_name, exp_name)\n",
    "    \n",
    "    # Phase 3: ML enhancement\n",
    "    if model is not None and scaler is not None:\n",
    "        features, feature_indices = create_features_for_ml(cumulative, stable_mask, exp_name)\n",
    "        \n",
    "        if len(features) > 0:\n",
    "            features_scaled = scaler.transform(features)\n",
    "            ml_predictions = model.predict(features_scaled)\n",
    "            \n",
    "            for i, prediction in enumerate(ml_predictions):\n",
    "                actual_idx = feature_indices[i]\n",
    "                if actual_idx < len(cleaned_series) and stable_mask[actual_idx]:\n",
    "                    if not np.isnan(prediction) and not np.isinf(prediction):\n",
    "                        # Blend ML prediction with penalized value\n",
    "                        cleaned_series[actual_idx] = prediction\n",
    "    \n",
    "    # Calculate statistics\n",
    "    original_std = np.std(cumulative)\n",
    "    cleaned_std = np.std(cleaned_series)\n",
    "    noise_reduction = (original_std - cleaned_std) / original_std * 100\n",
    "    correlation = np.corrcoef(cumulative, cleaned_series)[0, 1]\n",
    "    \n",
    "    return cleaned_series, outlier_mask, {\n",
    "        'outliers': outliers_count,\n",
    "        'noise_reduction': noise_reduction,\n",
    "        'correlation': correlation\n",
    "    }\n",
    "\n",
    "def apply_tuna_to_dataframe(df, exp_name, models, scalers, metric_name=\"\"):\n",
    "    \"\"\"Apply TUNA cleaning to each column in DataFrame\"\"\"\n",
    "    \n",
    "    exclude_cols = ['Time', 'Minutes', 'source']\n",
    "    value_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    column_results = {}\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    for col in value_cols:\n",
    "        col_values = df[col].values\n",
    "        model = models.get(col)\n",
    "        scaler = scalers.get(col)\n",
    "        \n",
    "        cleaned_values, outlier_mask, stats = apply_tuna_to_single_series(\n",
    "            col_values, exp_name, model, scaler, metric_name\n",
    "        )\n",
    "        \n",
    "        column_results[col] = {\n",
    "            'original': col_values,\n",
    "            'cleaned': cleaned_values,\n",
    "            'outliers': outlier_mask,\n",
    "            'stats': stats\n",
    "        }\n",
    "        \n",
    "        cleaned_df[col] = cleaned_values\n",
    "    \n",
    "    return cleaned_df, column_results\n",
    "\n",
    "def train_models_for_all_columns(metric_name, all_experiments):\n",
    "    \"\"\"Train RandomForest models for each column using stable periods\"\"\"\n",
    "    \n",
    "    exclude_cols = ['Time', 'Minutes', 'source']\n",
    "    first_df = list(all_experiments.values())[0]\n",
    "    value_cols = [col for col in first_df.columns if col not in exclude_cols]\n",
    "    \n",
    "    models = {}\n",
    "    scalers = {}\n",
    "    \n",
    "    for col in value_cols:\n",
    "        X_stable_all = []\n",
    "        y_stable_all = []\n",
    "        \n",
    "        for exp_name, df in all_experiments.items():\n",
    "            col_values = df[col].values\n",
    "            outlier_mask = detect_outliers_tuna_memory(col_values, metric_name=metric_name, experiment_type=exp_name)\n",
    "            stable_mask = ~outlier_mask\n",
    "            \n",
    "            features, feature_indices = create_features_for_ml(col_values, stable_mask, exp_name)\n",
    "            \n",
    "            if len(features) > 0:\n",
    "                stable_targets = col_values[feature_indices]\n",
    "                \n",
    "                valid_mask = ~(np.isnan(stable_targets) | np.isinf(stable_targets))\n",
    "                stable_features = features[valid_mask]\n",
    "                stable_targets = stable_targets[valid_mask]\n",
    "                \n",
    "                if len(stable_features) > 0:\n",
    "                    # Smooth targets with local median\n",
    "                    smoothed_targets = []\n",
    "                    for j, target in enumerate(stable_targets):\n",
    "                        start_idx = max(0, j-2)\n",
    "                        end_idx = min(len(stable_targets), j+3)\n",
    "                        local_values = stable_targets[start_idx:end_idx]\n",
    "                        smoothed_targets.append(np.median(local_values))\n",
    "                    \n",
    "                    X_stable_all.extend(stable_features)\n",
    "                    y_stable_all.extend(smoothed_targets)\n",
    "        \n",
    "        if len(X_stable_all) >= 10:\n",
    "            X_stable_all = np.array(X_stable_all)\n",
    "            y_stable_all = np.array(y_stable_all)\n",
    "            \n",
    "            # Clean data\n",
    "            nan_mask = np.isnan(y_stable_all) | np.isinf(y_stable_all)\n",
    "            if np.any(nan_mask):\n",
    "                X_stable_all = X_stable_all[~nan_mask]\n",
    "                y_stable_all = y_stable_all[~nan_mask]\n",
    "            \n",
    "            feature_nan_mask = np.isnan(X_stable_all).any(axis=1) | np.isinf(X_stable_all).any(axis=1)\n",
    "            if np.any(feature_nan_mask):\n",
    "                X_stable_all = X_stable_all[~feature_nan_mask]\n",
    "                y_stable_all = y_stable_all[~feature_nan_mask]\n",
    "            \n",
    "            if len(X_stable_all) >= 10:\n",
    "                scaler = StandardScaler()\n",
    "                X_scaled = scaler.fit_transform(X_stable_all)\n",
    "                \n",
    "                param_grid = {\n",
    "                    'n_estimators': [100],\n",
    "                    'max_depth': [5, 10, 15],\n",
    "                    'min_samples_split': [2, 5],\n",
    "                    'min_samples_leaf': [1, 2, 4],\n",
    "                    'max_features': ['sqrt', 'log2']\n",
    "                }\n",
    "                \n",
    "                model = RandomForestRegressor(\n",
    "                    criterion='squared_error',\n",
    "                    bootstrap=True,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=42\n",
    "                )\n",
    "                \n",
    "                grid_search = GridSearchCV(\n",
    "                    estimator=model,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='neg_mean_squared_error',\n",
    "                    cv=3,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=0\n",
    "                )\n",
    "                \n",
    "                grid_search.fit(X_scaled, y_stable_all)\n",
    "                models[col] = grid_search.best_estimator_\n",
    "                scalers[col] = scaler\n",
    "            else:\n",
    "                models[col] = None\n",
    "                scalers[col] = None\n",
    "        else:\n",
    "            models[col] = None\n",
    "            scalers[col] = None\n",
    "    \n",
    "    return models, scalers\n",
    "\n",
    "def run_tuna_analysis(all_datasets):\n",
    "    \"\"\"Run TUNA analysis on all datasets\"\"\"\n",
    "    \n",
    "    tuna_results = {}\n",
    "    \n",
    "    for metric_name, experiments in all_datasets.items():\n",
    "        \n",
    "        # Check experiments for variance\n",
    "        valid_experiments = {}\n",
    "        for exp_name, df in experiments.items():\n",
    "            exclude_cols = ['Time', 'Minutes', 'source']\n",
    "            value_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "            cumulative_values = df[value_cols].sum(axis=1).values\n",
    "            \n",
    "            has_variance = (np.std(cumulative_values) > 0 and len(np.unique(cumulative_values)) > 1)\n",
    "            if has_variance:\n",
    "                valid_experiments[exp_name] = df\n",
    "        \n",
    "        if not valid_experiments:\n",
    "            continue\n",
    "        \n",
    "        # Train models\n",
    "        models, scalers = train_models_for_all_columns(metric_name, valid_experiments)\n",
    "        \n",
    "        metric_results = {}\n",
    "        for exp_name, df in experiments.items():\n",
    "            if exp_name in valid_experiments:\n",
    "                # Apply TUNA cleaning\n",
    "                cleaned_df, column_results = apply_tuna_to_dataframe(\n",
    "                    df, exp_name, models, scalers, metric_name=metric_name\n",
    "                )\n",
    "                \n",
    "                total_outliers = sum(result['stats']['outliers'] for result in column_results.values())\n",
    "                \n",
    "                exclude_cols = ['Time', 'Minutes', 'source']\n",
    "                value_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "                \n",
    "                original_cumulative = df[value_cols].sum(axis=1).values\n",
    "                cleaned_cumulative = cleaned_df[value_cols].sum(axis=1).values\n",
    "                \n",
    "                original_std = np.std(original_cumulative)\n",
    "                cleaned_std = np.std(cleaned_cumulative)\n",
    "                noise_reduction = (original_std - cleaned_std) / original_std * 100 if original_std > 0 else 0\n",
    "                correlation = np.corrcoef(original_cumulative, cleaned_cumulative)[0, 1]\n",
    "                \n",
    "                overall_outlier_mask = np.zeros(len(df), dtype=bool)\n",
    "                for col_result in column_results.values():\n",
    "                    overall_outlier_mask |= col_result['outliers']\n",
    "                \n",
    "                metric_results[exp_name] = {\n",
    "                    'original': original_cumulative,\n",
    "                    'cleaned': cleaned_cumulative,\n",
    "                    'outliers': overall_outlier_mask,\n",
    "                    'stats': {\n",
    "                        'outliers': total_outliers,\n",
    "                        'noise_reduction': noise_reduction,\n",
    "                        'correlation': correlation\n",
    "                    },\n",
    "                    'column_results': column_results,\n",
    "                    'cleaned_df': cleaned_df\n",
    "                }\n",
    "            else:\n",
    "                # No cleaning for invalid experiments\n",
    "                exclude_cols = ['Time', 'Minutes', 'source']\n",
    "                value_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "                cumulative_values = df[value_cols].sum(axis=1).values\n",
    "                \n",
    "                metric_results[exp_name] = {\n",
    "                    'original': cumulative_values,\n",
    "                    'cleaned': cumulative_values,\n",
    "                    'outliers': np.zeros(len(df), dtype=bool),\n",
    "                    'stats': {\n",
    "                        'outliers': 0,\n",
    "                        'noise_reduction': 0.0,\n",
    "                        'correlation': 1.0\n",
    "                    },\n",
    "                    'column_results': {},\n",
    "                    'cleaned_df': df.copy()\n",
    "                }\n",
    "        \n",
    "        if metric_results:\n",
    "            tuna_results[metric_name] = metric_results\n",
    "    \n",
    "    return tuna_results\n",
    "\n",
    "def plot_tuna_results(tuna_results, all_datasets):\n",
    "    \"\"\"Plot TUNA results\"\"\"\n",
    "    \n",
    "    for metric_name, metric_results in tuna_results.items():\n",
    "        n_experiments = len(metric_results)\n",
    "        fig, axes = plt.subplots(n_experiments, 1, figsize=(15, 4*n_experiments))\n",
    "        \n",
    "        if n_experiments == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, (exp_name, results) in enumerate(metric_results.items()):\n",
    "            original = results['original']\n",
    "            cleaned = results['cleaned']\n",
    "            outliers = results['outliers']\n",
    "            stats = results['stats']\n",
    "            \n",
    "            df = all_datasets[metric_name][exp_name]\n",
    "            minutes = df['Minutes'].values\n",
    "            \n",
    "            # Plot data\n",
    "            axes[i].plot(minutes, original, 'b-', alpha=0.7, label='Original', linewidth=1)\n",
    "            axes[i].plot(minutes, cleaned, 'r-', alpha=0.8, label='TUNA Cleaned', linewidth=1.5)\n",
    "            \n",
    "            # Mark outliers\n",
    "            if np.any(outliers):\n",
    "                outlier_minutes = minutes[outliers]\n",
    "                outlier_original_values = original[outliers]\n",
    "                axes[i].scatter(outlier_minutes, outlier_original_values, \n",
    "                              color='red', s=8, alpha=0.8, marker='o', \n",
    "                              label=f'Outliers ({np.sum(outliers)})', zorder=5)\n",
    "            \n",
    "            # Labels based on CPU metrics\n",
    "            if 'iowait' in metric_name.lower():\n",
    "                y_label = 'CPU IOWait (msec)'\n",
    "            elif 'irq' in metric_name.lower():\n",
    "                y_label = 'CPU IRQ (msec)'\n",
    "            elif 'system' in metric_name.lower():\n",
    "                y_label = 'CPU System (msec)'\n",
    "            elif 'user' in metric_name.lower():\n",
    "                y_label = 'CPU User (msec)'\n",
    "            elif 'util' in metric_name.lower():\n",
    "                y_label = 'CPU Utilization (%)'\n",
    "            else:\n",
    "                y_label = 'CPU Values'\n",
    "            \n",
    "            axes[i].set_title(f'{metric_name} - {exp_name} (Noise Reduction: {stats[\"noise_reduction\"]:.1f}%, Outliers: {stats[\"outliers\"]})')\n",
    "            axes[i].set_xlabel('Minutes')\n",
    "            axes[i].set_ylabel(y_label)\n",
    "            axes[i].set_xlim(0, 120)\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle(f'TUNA Results: {metric_name}', fontsize=16, y=0.98)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()\n",
    "\n",
    "def print_tuna_summary(tuna_results):\n",
    "    \"\"\"Print TUNA summary\"\"\"\n",
    "    \n",
    "    print(f\"\\nTUNA Results Summary:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Metric':<15} {'Experiment':<15} {'Outliers':<10} {'Noise Red%':<12} {'Correlation':<12}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for metric_name, metric_results in tuna_results.items():\n",
    "        for exp_name, results in metric_results.items():\n",
    "            stats = results['stats']\n",
    "            print(f\"{metric_name:<15} {exp_name:<15} {stats['outliers']:<10} \"\n",
    "                  f\"{stats['noise_reduction']:>10.1f}% {stats['correlation']:>11.3f}\")\n",
    "\n",
    "def export_tuna_data_to_csv(tuna_results, export_dir=\"../../noise_reduction_data\"):\n",
    "    \"\"\"Export TUNA results to CSV\"\"\"\n",
    "    \n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    export_data = []\n",
    "    \n",
    "    for metric_name, metric_data in tuna_results.items():\n",
    "        for experiment_name, experiment_data in metric_data.items():\n",
    "            if 'stats' in experiment_data:\n",
    "                stats = experiment_data['stats']\n",
    "                export_data.append({\n",
    "                    'experiment_name': experiment_name,\n",
    "                    'metric': metric_name,\n",
    "                    'noise_reduction_pct': stats.get('noise_reduction', 0.0),\n",
    "                    'correlation': stats.get('correlation', 1.0),\n",
    "                    'outliers_removed': stats.get('outliers', 0),\n",
    "                })\n",
    "    \n",
    "    csv_filename = \"jvm_gateway_tuna_cpu.csv\"\n",
    "    csv_path = os.path.join(export_dir, csv_filename)\n",
    "    \n",
    "    df_simple = pd.DataFrame(export_data)\n",
    "    df_simple.to_csv(csv_path, index=False)\n",
    "    return csv_path\n",
    "\n",
    "def create_cleaned_csv_from_tuna_columns(original_df, column_results, metric_name, experiment_name, include_metadata=False):\n",
    "    \"\"\"Create a new DataFrame with TUNA-cleaned values\"\"\"\n",
    "    \n",
    "    cleaned_df = original_df.copy()\n",
    "    \n",
    "    exclude_cols = ['Time', 'Minutes', 'source']\n",
    "    value_cols = [col for col in cleaned_df.columns if col not in exclude_cols]\n",
    "    \n",
    "    total_outliers = 0\n",
    "    \n",
    "    for col in value_cols:\n",
    "        if col in column_results:\n",
    "            cleaned_values = column_results[col]['cleaned']\n",
    "            cleaned_df[col] = cleaned_values[:len(cleaned_df)]\n",
    "            total_outliers += column_results[col]['stats']['outliers']\n",
    "    \n",
    "    if include_metadata:\n",
    "        cleaned_df['tuna_processed'] = True\n",
    "        cleaned_df['tuna_total_outliers'] = total_outliers\n",
    "        cleaned_df['tuna_metric_name'] = metric_name\n",
    "        cleaned_df['tuna_experiment'] = experiment_name\n",
    "        \n",
    "        for col in value_cols:\n",
    "            if col in column_results:\n",
    "                outlier_mask = column_results[col]['outliers']\n",
    "                cleaned_df[f'tuna_outlier_{col}'] = outlier_mask[:len(cleaned_df)]\n",
    "                cleaned_df[f'tuna_noise_reduction_{col}'] = column_results[col]['stats']['noise_reduction']\n",
    "                cleaned_df[f'tuna_correlation_{col}'] = column_results[col]['stats']['correlation']\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "def export_all_cleaned_csvs(tuna_results, all_datasets, output_base_path=\"cleaned_cpu_data\", include_metadata=False):\n",
    "    \"\"\"Export all TUNA-cleaned datasets organized by experiment type\"\"\"\n",
    "    \n",
    "    output_base = Path(output_base_path)\n",
    "    output_base.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    created_files = {}\n",
    "    total_files = 0\n",
    "    \n",
    "    experiment_types = set()\n",
    "    for metric_results in tuna_results.values():\n",
    "        experiment_types.update(metric_results.keys())\n",
    "    \n",
    "    for exp_name in experiment_types:\n",
    "        exp_dir = output_base / exp_name\n",
    "        exp_dir.mkdir(exist_ok=True)\n",
    "        created_files[exp_name] = []\n",
    "    \n",
    "    for metric_name, metric_results in tuna_results.items():\n",
    "        for exp_name, results in metric_results.items():\n",
    "            original_df = all_datasets[metric_name][exp_name]\n",
    "            \n",
    "            if 'column_results' in results:\n",
    "                column_results = results['column_results']\n",
    "            else:\n",
    "                column_results = {}\n",
    "            \n",
    "            cleaned_df = create_cleaned_csv_from_tuna_columns(\n",
    "                original_df=original_df,\n",
    "                column_results=column_results,\n",
    "                metric_name=metric_name,\n",
    "                experiment_name=exp_name,\n",
    "                include_metadata=include_metadata\n",
    "            )\n",
    "            \n",
    "            csv_filename = f\"cpu_{metric_name.lower()}.csv\"\n",
    "            csv_path = output_base / exp_name / csv_filename\n",
    "            \n",
    "            cleaned_df.to_csv(csv_path, index=False)\n",
    "            created_files[exp_name].append(str(csv_path))\n",
    "            total_files += 1\n",
    "    \n",
    "    return created_files\n",
    "\n",
    "tuna_results = run_tuna_analysis(all_datasets)\n",
    "plot_tuna_results(tuna_results, all_datasets)\n",
    "print_tuna_summary(tuna_results)\n",
    "csv_path = export_tuna_data_to_csv(tuna_results)\n",
    "cleaned_files = export_all_cleaned_csvs(tuna_results, all_datasets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
